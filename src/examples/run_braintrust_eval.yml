description: >
  Run LLM evaluations with various platforms using the ai-evals orb
usage:
  version: 2.1
  orbs:
    ai-evals: circleci/ai-evals@0.0
  executors:
    python:
      working_directory: ~/project
      docker:
        - image: cimg/python:3.10
  jobs:
    aibraintrust-eval:
      executor: python
      steps:
        - checkout
        - run:
            name: install depedencies
            command: |
              pip install braintrust
              pip install -r ./experiments/ai-braintrust/requirements.txt
        - ai-evals/eval:
            eval_platform: braintrust
            circle_pipeline_id: << pipeline.id >>
            cmd: braintrust eval experiments/ai-braintrust/eval_tutorial.py
  workflows:
    ai-evals-workflow:
      jobs:
        - aibraintrust-eval:
            context:
              - context_name_where_eval_platform_specific_secrets_are_stored
              - context_name_where_github_token_secret_is_stored
